# Awesome BEV Perception from Multi-Cameras

<img src="https://github.com/chaytonmin/Awesome-BEV-Perception-Multi-Cameras/raw/main/photo/PETR.png" width="100%"/>

#### ECCV 2020
+ LSS: Lift, Splat, Shoot: Encoding Images from Arbitrary Camera Rigs by Implicitly Unprojecting to 3D [[paper](https://arxiv.org/pdf/2008.05711.pdf)] [[Github](https://github.com/nv-tlabs/lift-splat-shoot)] 

#### CoRL 2021
+ DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries [[paper](https://proceedings.mlr.press/v164/wang22b.html)] [[Github](https://github.com/WangYueFt/detr3d)] 

#### CVPR 2021
+ CaDDN:Categorical Depth Distribution Network for Monocular 3D Object Detection [[paper](https://arxiv.org/abs/2103.01100)] [[Github](https://github.com/TRAILab/CaDDN)] 

#### ICCV 2021
+ FIERY: Future Instance Prediction in Bird's-Eye View from Surround Monocular Cameras [[paper](https://arxiv.org/abs/2104.10490)] [[Github](https://github.com/wayveai/fiery)] 

#### CVPR 2022
+ CVT: Cross-view Transformers for real-time Map-view Semantic Segmentation [[paper](http://www.philkr.net/media/zhou2022crossview.pdf)] [[Github](https://github.com/bradyz/cross_view_transformers)] 

#### ICRA 2022 
+ Translating Images into Maps [[paper](https://arxiv.org/pdf/2110.00966.pdf)][[Github](https://github.com/avishkarsaha/translating-images-into-maps)]

#### ACMM 2022
+ Graph-DETR3D: Rethinking Overlapping Regions for Multi-View 3D Object Detection [[paper](https://arxiv.org/abs/2204.11582)]

#### ECCV 2022
+ BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers [[paper](https://arxiv.org/abs/2203.17270)] [[Github](https://github.com/zhiqi-li/BEVFormer)] 
+ PETR: Position Embedding Transformation for Multi-View 3D Object Detection [[paper](https://arxiv.org/pdf/2203.05625.pdf)][[Github]( https://github.com/megvii-research/PETR)]
+ SpatialDETR: Robust Scalable Transformer-Based 3D Object Detection from Multi-View Camera Images with Global Cross-Sensor Attention[[paper](https://markus-enzweiler.de/downloads/publications/ECCV2022-spatial_detr.pdf)] [[Github](https://github.com/cgtuebingen/SpatialDETR)]

#### 2022
+ BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View  [[paper](https://arxiv.org/pdf/2112.11790.pdf)] [[Github](https://github.com/HuangJunJie2017/BEVDet)] 
+ BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection [[paper](https://arxiv.org/abs/2203.17054)]
+ PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images [[paper](https://arxiv.org/abs/2206.01256)][[Github](https://github.com/megvii-research/PETR)]
+ M2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Birds-Eye View Representation [[paper](https://arxiv.org/abs/2204.05088)] 
+ BEVerse: Unified Perception and Prediction in Birds-Eye-View for Vision-Centric Autonomous Driving [[paper](https://arxiv.org/abs/2205.09743v1)] [[Github](https://github.com/zhangyp15/BEVerse)]
+ PolarDETR: Polar Parametrization for Vision-based Surround-View 3D Detection[[paper](https://arxiv.org/abs/2206.10965)] [[Github](https://github.com/hustvl/PolarDETR)]
+ (CoRL 2022) LaRa: Latents and Rays for Multi-Camera Bird's-Eye-View Semantic Segmentation [[paper](https://arxiv.org/abs/2206.13294)] [[Github](https://github.com/valeoai/LaRa)]
+ (AAAI 2023) PolarFormer: Multi-camera 3D Object Detection with Polar Transformers[[paper](https://arxiv.org/abs/2206.15398)] [[Github](https://github.com/fudan-zvg/PolarFormer)]
+ (ICRA 2023) CrossDTR: Cross-view and Depth-guided Transformers for 3D Object Detection[[paper](https://arxiv.org/abs/2209.13507)] [[Github](https://github.com/sty61010/CrossDTR)]
+ (AAAI 2023) BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection [[paper](https://arxiv.org/pdf/2206.10092v1.pdf)][[Github](https://github.com/Megvii-BaseDetection/BEVDepth)]
+ A Simple Baseline for BEV Perception Without LiDAR [[paper](https://arxiv.org/abs/2206.07959)] [[Github](https://github.com/aharley/simple_bev)]
+ BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View Recognition via Perspective Supervision [[paper](https://arxiv.org/abs/2211.10439)]
+ AeDet: Azimuth-invariant Multi-view 3D Object Detection [[paper](https://arxiv.org/abs/2211.12501)] [[Github](https://github.com/fcjian/AeDet)
+ (WACV 2023) BEVSegFormer: Bird’s Eye View Semantic Segmentation From Arbitrary Camera Rigs [[paper](https://arxiv.org/abs/2203.04050)] 

#### Longterm BEV
+ Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection [[paper](https://arxiv.org/abs/2210.02443)][[Github](https://github.com/Divadi/SOLOFusion)]
+ VideoBEV: Exploring Recurrent Long-term Temporal Fusion for Multi-view 3D Perception [[paper](https://arxiv.org/pdf/2303.05970.pdf)]
+ HoP: Temporal Enhanced Training of Multi-view 3D Object Detector via Historical Object Prediction [[paper](https://arxiv.org/abs/2304.00967)]
+ StreamPETR: Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection [[paper](https://arxiv.org/abs/2303.11926)][[Github](https://github.com/exiawsh/StreamPETR)]
+ SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos [[paper](https://arxiv.org/abs/2308.09244)][[Github](https://github.com/MCG-NJU/SparseBEV)]

#### BEV + Stereo
+ (AAAI 2023) BEVStereo: Enhancing Depth Estimation in Multi-view 3D Object Detection with Dynamic Temporal Stereo [[paper](https://arxiv.org/abs/2209.10248)] [[Github](https://github.com/Megvii-BaseDetection/BEVStereo)]
+ STS: Surround-view Temporal Stereo for Multi-view 3D Detection [[paper](https://arxiv.org/abs/2208.10145)]

#### End to End BEV Perception
+ ST-P3: End-to-end Vision-based Autonomous Driving via Spatial-Temporal Feature Learning [[paper](https://arxiv.org/abs/2207.07601)][[Github]( https://github.com/OpenPerceptionX/ST-P3)]
+ UniAD: Planning-oriented Autonomous Driving [[paper](https://arxiv.org/abs/2212.10156)][[Github](https://github.com/OpenDriveLab/UniAD)]

#### BEV + Distillation 
+ (ICLR 2023) BEVDistill: Cross-Modal BEV Distillation for Multi-View 3D Object Detection [[paper](https://arxiv.org/pdf/2211.09386.pdf)] [[Github](https://github.com/zehuichen123/BEVDistill)]
+ TiG-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning [[paper](https://arxiv.org/pdf/2212.13979.pdf)][[Github](https://github.com/ADLab3Ds/TiG-BEV)]

#### Robust BEV
+ RoboBEV: Towards Robust Bird's Eye View Detection under Corruptions
 [[paper](xxx)] [[Github](https://github.com/Daniel-xsy/RoboBEV)]

#### Fast BEV
+ Fast-BEV: A Fast and Strong Bird’s-Eye View Perception Baseline [[paper](https://arxiv.org/abs/2301.12511)] [[Github](https://github.com/Sense-GVT/Fast-BEV)]
+ MatrixVT: Efficient Multi-Camera to BEV Transformation for 3D Perception  [[paper](https://arxiv.org/abs/2211.10593)][[Github](https://github.com/Megvii-BaseDetection/BEVDepth)]

#### HD Map Construction
+ (ICRA 2022) HDMapNet: An Online HD Map Construction and Evaluation Framework [[paper](https://tsinghua-mars-lab.github.io/HDMapNet/)]  [[Github](https://github.com/Tsinghua-MARS-Lab/HDMapNet)]
+ (ICLR 2023) MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction [[paper](https://arxiv.org/abs/2208.14437)]  [[Github](https://github.com/hustvl/MapTR)]

#### Multi-sensor fusion
+ FUTR3D: A Unified Sensor Fusion Framework for 3D Detection [[paper](https://arxiv.org/abs/2203.10642)]  [[Github](https://github.com/Tsinghua-MARS-Lab/futr3d)]
+ (NeurIPS 2022) BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework [[paper](https://arxiv.org/abs/2205.13790)] [[Github](https://github.com/ADLab-AutoDrive/BEVFusion)]
+ (NeurIPS 2022) Unifying Voxel-based Representation with Transformer for 3D Object Detection [[paper](https://arxiv.org/pdf/2206.00630.pdf)] [[Github](https://github.com/dvlab-research/UVTR)]
+ BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation [[paper](https://bevfusion.mit.edu/)] [[Github](https://github.com/mit-han-lab/bevfusion)]
+ CMT: Cross Modal Transformer via Coordinates Encoding for 3D Object Dectection [[paper](https://arxiv.org/pdf/2301.01283.pdf)] [[Github](https://github.com/junjie18/CMT)]
+ BEVFusion4D: Learning LiDAR-Camera Fusion Under Bird's-Eye-View via Cross-Modality Guidance and Temporal Aggregation [[paper](https://arxiv.org/abs/2303.17099)]

#### Survey
+ Vision-Centric BEV Perception: A Survey [[paper](https://arxiv.org/pdf/2208.02797.pdf)]  [[Github](https://github.com/4DVLab/Vision-Centric-BEV-Perception)]
+ Delving into the Devils of Bird's-eye-view Perception: A Review, Evaluation and Recipe [[paper](https://arxiv.org/abs/2209.05324)][[Github](https://github.com/OpenPerceptionX/BEVPerception-Survey-Recipe)]

#### Occupancy Network
+ TPVFormer: An academic alternative to Tesla's Occupancy Network [[Github](https://github.com/wzzheng/TPVFormer)]

#### Pre-training
+ UniWorld: Autonomous Driving Pre-training via World Models [[paper](https://arxiv.org/abs/2308.07234)][[github](https://github.com/chaytonmin/UniWorld)]
+ Occ-BEV: Multi-Camera Unified Pre-training via 3D Scene Reconstruction [[paper](https://arxiv.org/abs/2305.18829)][[Github](https://github.com/chaytonmin/Occ-BEV)]
+ Occupancy-MAE: Self-supervised Pre-training Large-scale LiDAR Point Clouds with Masked Occupancy Autoencoders [[paper](https://arxiv.org/abs/2206.09900)][[Github](https://github.com/chaytonmin/Occupancy-MAE)]

#### others
+ Focal Sparse Convolutional Networks for 3D Object Detection [[paper](https://arxiv.org/abs/2204.12463)] [[Github](https://github.com/dvlab-research/FocalsConv)]
+ Voxel Field Fusion for 3D Object Detection [[paper](https://arxiv.org/abs/2205.15938)] [[Github](https://github.com/dvlab-research/VFF)]
+ Scaling up Kernels in 3D CNNs [[paper](https://arxiv.org/abs/2206.10555)] [[Github](https://github.com/dvlab-research/LargeKernel3D)]


### [nuScenes detection task Leaderboard](https://www.nuscenes.org/object-detection?externalData=all&mapData=all&modalities=Camera)

<img src="https://github.com/chaytonmin/Awesome-BEV-Perception-Multi-Cameras/raw/main/photo/nuscenes.png" width="100%"/>
