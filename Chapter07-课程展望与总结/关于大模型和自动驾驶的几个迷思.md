<!--
 * @Author: Charmve yidazhang1@gmail.com
 * @Date: 2023-10-10 10:49:30
 * @LastEditors: Charmve yidazhang1@gmail.com
 * @LastEditTime: 2024-01-24 13:54:28
 * @FilePath: /OccNet-Course/Chapter07-课程展望与总结/关于大模型和自动驾驶的几个迷思.md
 * @Version: 1.0.1
 * @Blogs: charmve.blog.csdn.net
 * @GitHub: https://github.com/Charmve
 * @Description: 
 * 
 * Copyright (c) 2023 by Charmve, All Rights Reserved. 
 * Licensed under the MIT License.
-->

23年的AI绕不开的问题就是大模型，最近私下以及在几个workshop上反复和各种同学讨论相关的问题。借这个机会也整理一下几点个人的看法和大家分享讨论~

## Q1: 究竟什么是大模型？参数量或计算量大就叫大模型吗？Large Model or Foundation Model？
A1: 其实在讨论所有关于大模型的问题之前，都需要明确这个问题。大模型（Large Model）这个名词其实是一个非常误解的名字，其实更准确的应该是基石模型（Foundation Model）。经常发现和很多人聊了很久，观点针锋相对，最后发现双方根本讨论的不是一个东西。。。就目前而言，我认为的大模型至少要有两个要素：1) 跨任务的通用性 2) 跨域的通用性。参数量和计算量的scale up只是大模型的一个必要而不充分条件。以GPT为代表的NLP大模型，通过prompt来统一了不同任务，也通过利用了基本上所有可用的文本数据将所有NLP问题变成了域内问题。

如果我们以这个标准来讨论，就会发现其实现在很多所谓的大模型，都不能叫做大模型。去讨论这样的模型到底能做什么，边界在哪里自然就是一个没有意义的事情。如果能理解这点，很多所谓的行业大模型本身就会成为一个伪命题，只能叫做通用大模型在垂直行业的一个应用（当然这件事情本身很多时候也是有商业价值的）。而反过来讲，想只靠某些垂直领域的数据去训练一个所谓的行业大模型不如叫做小模型或者专业模型变大，这和大家在讨论的Foundation Model就是完全不同的两个东西。

## Q2: 目前视觉领域存在这样的大模型吗？如果没有可能的原因是什么？
A2: 很遗憾，虽然这方面已经有了很多如CLIP或DINO之类的尝试和进展，但是目前对于CV而言，还远未到达ChatGPT时刻。究其原因，本质还是视觉信息与语言信息这两者在信息密度上的巨大差异。语言只需要考虑一维上（前后文）的context，然而视觉需要考虑在三维（2D图像的x y和时间）的context。这会使得context信息密度的急剧下降，对于需要的数据量和计算量有指数级的上升。说到底，语言毕竟还是人的逻辑思考的产物，而图像或者视频则完全是自然的展现。具体到技术层面上来说，也有若干没有确定答案的open问题：

什么是最合适的监督形式？年初SAM带火了一波视觉大模型，但其实本质上仍然是监督学习的范式。做的事情也是在工程上推到极致，通过这样的方式继续scale up的难度是非常大的。而现在视觉自监督最常见的两种范式Contrastive Learning和Masked Autoencoder也遇到了继续scale的难题：似乎视觉模型随着参数量和计算量的增加并没有出现语言模型的Grokking现象，甚至随着规模的scale up性能出现了一定程度的饱和。这和在NLP里面的大力出奇迹的表现非常不同，究竟是规模还不够大，还是因为这样的监督方式就有问题，目前还不得而知。

多任务的表示形式怎么统一？这一点其实是在一次的panel上 @代季峰 老师提到的。在NLP中我们可以通过prompt的形式把基本上所有的NLP任务统一成text to text的形式，但是CV中呢？naive地类比成image to image translation显然会存在很多的问题。没有统一的表示使得多任务很难共享同样的网络，仍然需要单独训练不同任务的head，使得模型的泛化性大大降低。

不敢妄言视觉大模型正确的思路是什么，但是可以分享一些我认为的视觉大模型该考虑到的一些点或者说具有的一些性质：以自监督为范式，时序和3D为基础，能预测物理世界。第一点是scale up的基础，无需多言。第二三点其实我认为是目前所有视觉预训练模型都没有解决的一个核心问题，也是打通low level vision与high level vision的一个关键的桥梁。现有的视觉预训练数据基本都来自于单帧的web data，这和在自然物理世界中会遇到的数据分布其实是有巨大的差异的。而CV和NLP我认为最大的区别就在于，CV的大模型最终极的目标是能和这个物理世界产生互动，能够理解这个物理世界中的常识。为了达到这个目标，只使用单帧的web data是显然不行的。在这个方向上，SFMLearner是一个很好的尝试，解决了low level vision自监督中的一些问题，但是仍然没有向上去解决high level的语义问题。希望在这个角度上，能看到更多有意义的尝试。

Q3: 现在有很多大语言模型在机器人领域的尝试，这是否意味着传统的规划控制会被全数据驱动的方法取代？
A3: Of course no! 以有限的对LLM for robotics的了解，现在的工作大致可以分为两类：1) 用LLM作为一个更好的环境理解与人机交互的接口。2) 用LLM + Neural Symbolic的方法去做task planning。在这两个方向上确实LLM取得了很好的进展，但是这就是规划和控制的全部吗？分享一些我能看到的问题：

更底层的运动控制与规划是一个被well solved的问题吗？目前还没看到有什么证据表明LLM可以直接去控制一些复杂的被控目标。和执行器打交道的更底层控制，仍然需要对被控对象进行精细的建模。我也不相信Boston Dynamic这样的公司真的会去用大模型去解决这些复杂的底层控制问题。

现在看到的应用中基本上都是对于静态环境与静态的agent交互。对于更复杂的POMDP，目前并没看到有什么相关的尝试。这恰恰算是在规划控制问题中一类常见的问题，例如无人车的规划，竞技类的棋牌游戏亦或是星际争霸。这样的一些任务中，状态空间巨大，也需要对不确定性进行很好的建模。目前也没看到LLM能够通过一些prompt的形式实现这样的功能。

所以总结一下，LLM for robotics确实有很多有价值的应用，尤其是在任务理解和规划层面，但是想完全取代也是不现实的。

Q4: 端到端自动驾驶算不算大模型？都拿了CVPR best paper了，你们L4为什么不跟进？
A4: Well，如果以Q1中的定义的话确实不算。除了实际的一些工程问题之外，其实在L4中不去这样做的一个核心问题还是在于可靠性。在很多场合我都表达过追求全系统的端到端对于L2来说是可行的，但是对于L4是不适合的。L2系统很多时候可以在效率与安全之间tradeoff，但是L4系统的设计目标则是在保证worst case安全的前提下来优化效率。显然，任何一个纯数据驱动的feedforward系统是不会有这样保证的。为了达到这样的安全目标，我们必然要去在系统设计层面设计足够多的算法冗余，这就会打破端到端的模式。更详细的阐述见我之前写的这篇文章：

Naiyan Wang：海量数据就是高级别自动驾驶的银弹吗？
https://zhuanlan.zhihu.com/p/384804813

最后，为了防杠，想补充的一点是，上下游协同设计和优化的这个思想我认为是非常正确和有意义的，只不过在部署端一定会存在模块化的冗余。在这一点上，还是有很多有意义的方向可以尝试，除了常见一些模块之间的表示与接口有很大的优化空间，就算在端到端方向也有一些有意义的问题：第一，怎样把一些行为有保障的planner（一般会是一个非凸的优化问题） formulate成对输入可导的形式，从而指导上游模块的学习？这样系统就不是一个纯feedforward了，从而可以加入各种约束和保证。我们之前在多目标追踪方向上做过这样的一些尝试，但是这个问题中的优化形式相比于planner还是过于toy了。第二，如何评测一个端到端训练的系统输出以便可以比较？在端到端的系统中，传统的感知评测的metric都已经不再适用。期待在这些问题上能有一些突破性的进展。

Q5: 那大模型在自动驾驶中可能有哪些应用？有没有实际落地的场景呢？
A5: 在车端而言，我确实没看到有什么去做部署的可能。一方面是实际算力的问题，一方面是并没看到一个特别清晰的杀手锏应用，也就是说没看到什么现在车端小模型一定解决不了但是大模型可以解决的问题。换句话说，如果给一台8卡A100在车上跑，L4自动驾驶就做出来了吗？答案显然不是的。但是在离线场景中，确实大有可为。这面最典型的应用可能就是数据集和corner case的检索与扩充。这个在 @王井东 老师在Apollo Day上有详细的介绍，我们做过一些类似的尝试，也取得了很不错的效果。除此之外，在预标注和自动标注方向也有很多的应用，也可以用更直接的model distill的方法来辅助在线模型的训练。总结下来，核心思想都是通过无论是数据还是特征的方式，将大模型更强的表征能力赋予在线的模型。也期待后续能有一些更新的范式出现，解决在线场景中的一些棘手的问题。但所有这些的前提都是大模型真的可以可靠解决小模型解决不了的问题。

在2023.7这个时间点来mark一下现在的认知，可能随着技术的发展有很多东西都要被打脸，也欢迎大家评论区理性讨论，观点碰撞~